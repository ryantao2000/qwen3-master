{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74831356-fef5-4a24-9378-5e3637efbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n qwen3 python=3.10 -y\n",
    "conda activate qwen3\n",
    "\n",
    "pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "pip install \"transformers>=4.51.0\" accelerate tokenizers safetensors sentencepiece einops protobuf numpy scipy\n",
    "\n",
    "pip install \"vllm==0.9.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8fd391-051e-4e54-b178-5ed091ce9b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.7.0+cu126 CUDA available: True\n",
      "Transformers: 4.55.4\n",
      "GPU: NVIDIA vGPU-48GB\n"
     ]
    }
   ],
   "source": [
    "# 验证安装\n",
    "import torch, transformers\n",
    "print(\"Torch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8863ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: <think>\n",
      "Okay, the user asked for a short introduction to large language models. Let me start by recalling what I know about them. Large language models are a type of AI that can understand and generate human-like text. They're trained on vast amounts of data, right? I should mention things like natural language processing and machine learning.\n",
      "\n",
      "Wait, maybe I should define what a large language model is first. They're part of the broader field of NLP, but they're specifically large-scale. The key points are their size, the training data, and their capabilities. Oh, and they can do tasks like answering questions, writing stories, coding, etc. \n",
      "\n",
      "I need to make sure I explain why they're called \"large.\" Probably because they have a huge number of parameters, which allows them to capture complex patterns in language. Also, they're trained on diverse data sources, which helps them handle various tasks. \n",
      "\n",
      "But I should keep it concise since the user wants a short intro. Maybe start with the definition, then mention their training process, capabilities, and applications. Avoid technical jargon as much as possible. Let me check if I'm missing anything important. Oh, maybe mention that they're used in different industries, like customer service, content creation, etc. \n",
      "\n",
      "Wait, should I include examples of models like GPT or BERT? The user didn't ask for specific models, just an introduction. Maybe it's better to keep it general. Also, highlight their ability to understand context and generate coherent responses. \n",
      "\n",
      "I need to structure this clearly. Start with a definition, explain how they're trained, their capabilities, and their uses. Keep each part brief. Let me put that together in a few sentences. Make sure it's easy to understand without being too technical. Alright, that should cover the essentials.\n",
      "</think>\n",
      "\n",
      "Large language models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language. Trained on vast amounts of text data, they use deep learning techniques to recognize patterns, context, and relationships in language, enabling them to perform tasks like answering questions, creating content, coding, and even engaging in conversations. Their \"large\" scale refers to their immense parameter count and training data, which allows them to handle complex tasks with high accuracy and adaptability across diverse domains. LLMs are revolutionizing fields like customer service, education, and creative writing by bridging the gap between human and machine communication.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/root/autodl-tmp/Qwen/Qwen3-8B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=16384\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm服务调用\n",
    "\n",
    "vllm serve /root/autodl-tmp/Qwen/Qwen3-8B --dtype auto --port 6006  --max_model_len 8784 --gpu_memory_utilization 0.8\n",
    "\n",
    "# 端口映射 本地上打开8000端口 注意复制密码\n",
    "ssh -CNg -L 8000:127.0.0.1:6006 root@connect.bjb1.seetacloud.com -p 19434\n",
    "\n",
    "nviHq5jZ1kQW\n",
    "222\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import base64\n",
    "import time\n",
    " \n",
    "def encode_image(image_path):       # 编码本地图片的函数\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    " \n",
    "start = time.time()\n",
    "# 1.url\n",
    "url = 'http://localhost:8000/v1/chat/completions'\n",
    " \n",
    " \n",
    "# 2.data\n",
    "## 2.1如果server.py启动，用这个data\n",
    "data = {\"model\": \"Qwen3-8B\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},     # 系统命令，一般不要改\n",
    "                     {\"role\": \"user\",\n",
    "                      \"content\": \"Tell me something about large language models.\"}],    # 用户命令，一般改这里\n",
    "        \"temperature\": 0.7,\"top_p\": 0.8,\"repetition_penalty\": 1.05,\"max_tokens\": 1024}\n",
    " \n",
    " \n",
    "# 3.将字典转换为 JSON 字符串\n",
    "json_payload = json.dumps(data)\n",
    " \n",
    " \n",
    "# 4.发送 POST 请求\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json_payload, headers=headers)\n",
    " \n",
    "\n",
    "# 5.打印响应内容\n",
    "print(response.json().get(\"choices\", [])[0].get(\"message\", []).get(\"content\", []))\n",
    "# print(response.json())        # 调试用\n",
    " \n",
    "print(\"\\n总时间：\", time.time()-start, \"秒\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
